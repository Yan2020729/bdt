### bdt
The R package **bdt** implements adapted bootstrap diagnostic tool (BDT), originally described in Bahamyirou A, Blais L, Forget A, Schnitzer ME. *Understanding and diagnosing the potential for bias when using machine learning methods with doubly robust causal estimators*. \emph{Statistical Methods in Medical Research}. 2019 Jun;28(6):1637-50. This **bdt** package is to identify the instability in the estimation of marginal causal effects in the presence of near practical positivity violations. Data-adaptive methods can produce a separation of the two exposure groups in terms of propensity score densities which can lead to biased finite-sample estimates of the treatment effect. **bdt** is based on a bootstrap resampling of the subjects and simulation of the outcome data conditional on observed treatment and covariates in order to diagnose whether the estimation using data-adaptive methods for the propensity score may lead to large bias and poor coverage in the finite sample. For more theoretical details, please refer to the original paper: https://doi.org/10.1177%2F0962280218772065.

## Parameter of interest and Positivity assumption 

In the context of causal inference, identifiability of causal effects requires some untestable assumptions that allow investigators to write the parameter of interest in terms of the distribution of the observational studies. The common assumptions include stable unit treatment value assumption, consistency, ignorability and positivity. Consider an observational data with $n$ i.i.d. observations on the data structure $O = (X, A, Y)$, where $X$ be the vector of baseline covariates of an individual; $A$ be the observed binary treatment indicator with the value equals to 1 if the subject received the treatment and 0 otherwise; $Y$ be the observed continuous or binary outcome. The parameter of interest is the additive effect conditioning on a set of potential confounders $X$. Positivity assumption requires that the probability of receiving any level of treatment conditioning on every set of covariates must be positivity for all subjects in the population, i.e. $P(A=a|X)>0$ for any $a\in\{0,1\}$. 

## Estimation

In this package, to estimate the average treatment effect (ATE), we use the inverse probability of treatment weighting (IPTW), augmented inverse probability of treatment weighted estimator (A-IPTW) and Targeted Maximum Likelihood Estimators (TMLEs). To estimate the unbiased or consistent estimator, the correct specification of treatment assignment model is required for IPTW. Doubly robust estimators A-IPTW and TMLE decrease the dependence on the correct specification of the propensity model and only require either outcome model or propensity score model to be correctly specified. 

In practice, researchers are typically unaware of the true specification of the propensity score model. To increase the chance of correct model specification, flexible prediction methods, in particular the ensemble learner called 'SuperLearner' (SL), are often recommended. SL is a nonparametric methodology that uses cross validation to find an optimal convex combination of the predictions of a library of candidate algorithms defined by the user. However, the flexibility in the propensity modeling can lead to the selection of strong predictors of the treatment. This would give rise to extreme value of propensity score since these predictors may or may not be real confounders. Both A-IPTW and TMLE involve the inverse of propensity scores and practical positivity violations can lead to unstable parameter estimates and potential bias due to highly variable weights. In order to address this issue, one may define different bounds to truncate the probabilities then reduce their standard errors though choice of truncation level is usually ad-hoc.

## Bootstrap diagnostic tool

Furthermore, in the presence of potential positivity violations, flexible modeling of the propensity score give rise to the increment of the bias and variance of the causal effect estimators as compared to parametric methods and the extent of how much they are impacted depends on the estimator. Bahamyirou et al. presented an adapted version of the diagnostic tool proposed by Peterson et al. in simulated data to illustrate whether the ATE estimators were destablized by the use of SL to fit the propensity score. For a given observed data set, the diagnostic tool which is based on a bootstrap resampling of the subjects, keeps the observed treatment of each resampled subject but simulates the outcome using the information of the two observed subgroups who are treated or not being treated. To expedite the application of this diagnostic tool, we develop **bdt** package to diagnose the instability introduced when machine learning is employed for the estimation of the propensity score. 


## Stages 

- Stage 1: Propensity scores estimation. For a given observed dataset $(Y, A, X)$ with $n$ i.i.d. observations where the outcome $Y$ is either a continuous or a binary variable, the treatment $A$ is a binary variable and $X$ could be a vector, matrix or dataframe containging baseline covariates, the propensity scores are estimated by logistic regression and/or SL methods. 
- Stage 2: Fitting outcome models. For the two treatment subgroups of subjects with $A=1$ and $A=0$, fit a linear regression of the outcome $Y$ on baseline covariates $X$ respectively where the model only contains main terms of $X$. We denote the estimated coefficients and their corresponding variance as $\hat{\beta}_{0,a}$, $\hat{\beta}_{X,a}$ and $\hat{\sigma}^2_a$ for the realization of treatment $a\in\{0,1\}$.
- Stage 3: Computing the "true" effect for the bootstrap data generating distribution $\hat{P}_0$. It is obtained by computing the difference of the two potential outcomes for all subjects using the estimated coefficients from 2nd step.
- Stage 4: Simulation of the bootstrap datasets. Sample the $n$ subjects with replacement then replace their observed outcomes with new outcome values which are estimated based on the coefficients obtained in the 2nd step. Specifically, if the outcome $Y$ is continuous,  the two potential outcomes $Y^1$ and $Y^0$ are generated from a $\mathcal{N}(\mu_a, \sigma^2_a)$ distribution with mean $\mu_a=\hat{\beta}_{0,a}+X\hat{\beta}_{X,a}, a\in\{0,1\}$. Similarly, if $Y$ is binary, $Y^1$ and $Y^0$ are generated from a $Binomial(n_a, p_a)$ distribution where $n_a$ represents the number of subjects with $A=a$ in the resampled data and $logit(p_a)=\hat{\beta}_{0,a}+X\hat{\beta}_{X,a}, a\in\{0,1\}$. 
- Stage 5: Estimation of target parameters. For the resampled data with simulated outcomes, three candidate estimators TMLE, A-IPTW and IPTW are applied to estimate the targeted parameter using the``true'' specification of the outcome model (same with the linear regression model in step 2) and the propensity score is modeled by logistic regression and/or SL. User could define specific bounds for the values of $g_n$ where the default value is 0.025. 
- Stage 6: Repeat steps (3) and (5) $M$ times. Then bias could be calculated by comparing the mean of the estimators $\hat{\psi}$ across $M$ bootstrap samples with the true value of the target parameter under the bootstrap data generating distribution. Also, the coverage rates of three estimators are obtained based on the $95\%$ confidence intervals.


