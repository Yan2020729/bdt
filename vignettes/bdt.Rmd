---
title: "Introduction to bdt()"
author: "Yan Liu"
date: "`r Sys.Date()`"
output: html_document
vignette: >
  %\VignetteIndexEntry{bdt}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
library(bdt)
```

The R package **bdt** implements adapted bootstrap diagnostic tool (BDT), originally described in Bahamyirou A, Blais L, Forget A, Schnitzer ME. *Understanding and diagnosing the potential for bias when using machine learning methods with doubly robust causal estimators*. \emph{Statistical Methods in Medical Research}. 2019 Jun;28(6):1637-50. Data-adaptive methods can produce a separation of the two exposure groups in terms of propensity score densities which can lead to biased finite-sample estimates of the treatment effect. **bdt** is based on a bootstrap resampling of the subjects and simulation of the outcome data conditional on observed treatment and covariates in order to diagnose whether the estimation using data-adaptive methods for the propensity score may lead to large bias and poor coverage in the finite sample. For more theoretical details, please refer to the original paper: https://doi.org/10.1177%2F0962280218772065.

## Parameter of interest and Positivity assumption 

In the context of causal inference, identifiability of average treatment effects requires some assumptions that allow investigators to write the parameter of interest in terms of the distribution of the observational studies. The common assumptions include consistency, ignorability and positivity. Consider an observational data with $n$ i.i.d. observations on the data structure $O = (W, A, Y)$, where $W$ be the vector of baseline covariates of an individual; $A$ be the observed binary treatment indicator with the value equals to 1 if the subject received the treatment and 0 otherwise; $Y$ be the observed continuous or binary outcome. The parameter of interest is the additive effect conditioning on a set of potential confounders $W$. Positivity assumption requires that the probability of receiving any level of treatment conditioning on every set of covariates must be positivity for all subjects in the population, i.e. $P(A=a|W)>0$ for any $a\in\{0,1\}$. 

## Estimation

In this package, we use two estimators: augmented inverse probability of treatment weighted estimator (A-IPTW) and Targeted Maximum Likelihood Estimators (TMLEs) to estimate the average treatment effect (ATE). Doubly robust estimators A-IPTW and TMLE decrease the dependence on the correct specification of the propensity model and only require either outcome model or propensity score model to be correctly specified. 

In practice, researchers are typically unaware of the true specification of the propensity score model. To increase the chance of correct model specification, flexible prediction methods, in particular the ensemble learner called 'SuperLearner' (SL), are often recommended. SL is a non-parametric methodology that uses cross validation to find an optimal convex combination of the predictions of a library of candidate algorithms defined by the user. However, under some settings the flexibility in the propensity modeling can lead to the selection of strong predictors of the treatment. This would give rise to extreme value of propensity score since these predictors may or may not be real confounders. Since both A-IPTW and TMLE involve the inverse of propensity scores, the practical positivity violations can lead to unstable parameter estimates and potential bias due to highly variable weights. Overall, in the presence of potential positivity violations, flexible modeling of the propensity score give rise to the increment of the bias and variance of the causal effect estimators as compared to parametric methods and the extent of how much they are impacted depends on the estimator. In order to address this issue, one may define different bounds to truncate the probabilities then reduce their standard errors though choice of truncation level is usually ad-hoc.

## Bootstrap diagnostic tool

Bahamyirou et al. presented an adapted version of the diagnostic tool in simulation to illustrate whether the ATE estimators were destablized by the use of SL to fit the propensity score. For a given observed data set, the diagnostic tool which is based on a bootstrap resampling of the subjects, keeps the observed treatment of each resampled subject but simulates the outcome using the information of the two observed subgroups who are treated or not being treated. To expedite the application of this diagnostic tool, we develop **bdt** package to diagnose the instability introduced when machine learning is employed for the estimation of the propensity score. 


## Stages 

- Stage 1: Propensity scores estimation. For a given observed data $(W, A, Y)$ with $n$ i.i.d. observations where the outcome $Y$ is either a continuous or a binary variable, the treatment $A$ is a binary variable and $W$ could be a vector, matrix or data frame containing baseline covariates, the propensity scores are estimated by logistic regression and/or SL methods. 
- Stage 2: Fitting outcome models. For the two treatment subgroups of subjects with $A=1$ and $A=0$, fit a linear regression of the outcome $Y$ on baseline covariates $W$ respectively where the model only contains main terms of $W$. We denote the estimated coefficients and their corresponding variance as $\hat{\beta}_{0,a}$, $\hat{\beta}_{W,a}$ and $\hat{\sigma}^2_a$ for the realization of treatment $a\in\{0,1\}$.
- Stage 3: Computing the "true" effect for the bootstrap data. It is obtained by computing the difference of the two potential outcomes for all subjects using the estimated coefficients from 2nd step.
- Stage 4: Simulation of the bootstrap datasets. Sample the $n$ subjects with replacement then replace their observed outcomes with new outcome values which are estimated based on the coefficients obtained in the 2nd step. Specifically, if the outcome $Y$ is continuous,  the two potential outcomes $Y^1$ and $Y^0$ are generated from a $\mathcal{N}(\mu_a, \sigma^2_a)$ distribution with mean $\mu_a=\hat{\beta}_{0,a}+W\hat{\beta}_{W,a}, a\in\{0,1\}$. Similarly, if $Y$ is binary, $Y^1$ and $Y^0$ are generated from a $Binomial(n_a, p_a)$ distribution where $n_a$ represents the number of subjects with $A=a$ in the resampled data and $logit(p_a)=\hat{\beta}_{0,a}+W\hat{\beta}_{W,a}, a\in\{0,1\}$. 
- Stage 5: Estimation of target parameters. For the resampled data with simulated outcomes, two estimators TMLE and A-IPTW are applied to estimate the targeted parameter using the``true'' specification of the outcome model (same with the linear regression model in step 2) and the propensity score is modeled by logistic regression and/or SL. User could define specific bounds for the values of $g_n$ where the default value is 0.025. 
- Stage 6: Repeat steps (4) and (5) $M$ times. Then errors could be calculated by comparing the mean of the estimators $\hat{\psi}$ across $M$ bootstrap samples with the ``true'' value of the bootstrap data. Also, the influence function based standard errors and the coverage rates of two estimators are computed based on the $95\%$ confidence intervals $M$ bootstrap samples.


## Example

We use the example as described in the simulation part of Bahamyirou's paper. In this data, outcome $Y$ is a continuous variable and treatment $A$ is binary with realizations $a \in\{ 1, 0\}$. The baseline covariate set $X$ contains five elements ($W_1, W_2$, $I_1, I_2, P$) where $W_1, W_2$ are two confounders, $P$ is a pure risk factor and $I_1, I_2$ are two instruments. We generate a single data set by setting seed to 1250.

```{r}
set.seed(1250)
n = 1000
sigma = matrix(c(2, 1, 1, 1), ncol = 2)
W = matrix(rnorm(n*2), ncol = nrow(sigma)) %*% chol(sigma)
W = W + matrix(rep(c(.5, 1),each = n), byrow = FALSE, ncol = 2)
bound = function(x, bounds){
  x[x < min(bounds)] = min(bounds); x[x > max(bounds)] = max(bounds)
  return(x)}
I1 = bound(rnorm(n,mean = 1, sd = 2), c(-3,3))
I2 = bound(rnorm(n,mean = 1, sd = 1.9), c(-3,3))
P = bound(rnorm(n,mean = 1, sd  =1.5), c(-3,3))
X = data.frame(W, I1, I2, P)
colnames(X) = c("W1", "W2", "I1", "I2",  "P")
X$W1 <- bound(X$W1,c(-3,4)); X$W2 <- bound(X$W2,c(-3,4))
A = rbinom(n, 1, plogis(0.2 + X[,"W1"] + 0.3*X[,"I1"] + X[,"W1"]*X[,"I1"] 
                         - 0.2*(X[,"W2"] + X[,"I2"])^2 ))
Y = 1 + A + X[,"W1"] + 2*X[,"W2"] + 0.5*(X[,"W1"] + X[,"P"])^2 + rnorm(n)
```

We start with the estimation of propensity scores. We define two GLM regression formulas and one vector of SL prediction algorithms where gform1 only contains the main terms and gform2 includes two more interactions $W_1\times I_1$ and $W_2\times I_2$. SL library includes four methods: ``glm'', ``gam'', ``glmnet'' and ``glm.interaction''. No bounds are set to the probabilities of treatment. Then running by ***summary(ps)***, ***plot(ps)***, we can obtain the summary and plots of all probabilities. In addition, the fitted summaries of the three models can be displayed by ***ps$fit_summaries***. 

```{r, message=FALSE}
ps = ps(A, X, gform1 = "A~ W1+W2+I1+I2", gform2 = "A~ W1*I1+W2*I2", 
         SL.library1 = NULL, 
         SL.library2 = c("SL.glm", "SL.glmnet", "SL.gam", "SL.glm.interaction"),
         verbose = TRUE)
summary(ps)
plot(ps)
ps$fit_summaries
```

Next we use ***bdt*** function to simulate totally 10 bootstrap data sets to estimate the average error of estimators A-IPTW and TMLE and corresponding coverage rates using SL and GLM where the outcome models and the propensity models are included only with main terms (no bounding). We store the results as the objects $bdt\_glm$ and $bdt\_sl$ respectively. Since we only generate 10 data here, a message "Small number of replications may lead to unreliable estimates." shows up. Then we also apply ***summary()***, ***plot()*** to two objects to compare the mean errors and coverage rates of two estimators.


```{r, warning=FALSE }
qform = "Y~A+W1+W2+P"
gform = "A~W1+W2+I1+I2"
bdt_glm = bdt(Y, A, X, M = 10, outcome_type = "continuous", 
                Qform = qform, gbound = 0, gGLM = TRUE, gform = gform)
summary(bdt_glm)
plot(bdt_glm)

lib = c("SL.gam", "SL.glm.interaction")
bdt_sl = bdt(Y, A, X, M = 10, outcome_type = "continuous", Qform = qform, 
           gbound = 0, gGLM = FALSE, SL.library = lib)
summary(bdt_sl)
plot(bdt_sl)
```


## Acknowledgement

This project would have been infeasible without guidance and helps from Mireille Schnitzer and Asma Bahamyirou for package and coding suggestions, Hadley Wickham for his two great books **Advanced R** and **R Packages**. 



